{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f117c6b-7048-462c-809b-34d840167005",
   "metadata": {},
   "source": [
    "# Prototype MAF\n",
    "\n",
    "# XXX-Looks like trying to use pandas at all causes a memory leak? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7af750-6b42-4259-a154-d9d799b3981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from slicer import Slicer, MeanMetric, CountMetric, CoaddM5Metric, PlotMoll, gen_summary_row\n",
    "from rubin_sim.data import get_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a3eb24-3a54-4e8d-9a83-a108cf5873e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a small example visit history\n",
    "baseline_file = get_baseline()\n",
    "\n",
    "con = sqlite3.connect(baseline_file)\n",
    "#df = pd.read_sql(\"select * from observations where night < 61;\", con)\n",
    "df = pd.read_sql(\"select * from observations;\", con)\n",
    "#df = pd.read_sql(\"select observationID,fieldRA,fieldDec,night,fiveSigmaDepth,filter,rotSkyPos from observations;\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbd265-b0d9-4574-9f8f-9bece2307940",
   "metadata": {},
   "source": [
    "# 6 depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a3c448-8995-4173-a471-f41806d5b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#summary_stats = []\n",
    "subsets = {}\n",
    "for filtername in 'ugrizy':\n",
    "    subsets[filtername] = np.where(df[\"filter\"] == filtername)[0]\n",
    "#subsets[\"all\"] = np.arange(np.size(df[\"filter\"]))\n",
    "\n",
    "for key in subsets:\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    sub_data = df.iloc[np.where(df[\"filter\"] == filtername)[0]]\n",
    "    metric = CoaddM5Metric(unit=\"Coadd %s (mags)\" % filtername)\n",
    "    sl = Slicer(nside=128)\n",
    "    hp_array, info = sl(sub_data, metric, info=info)\n",
    "    #summary_stats.append(gen_summary_row(info, \"mean\", np.nanmean(hp_array)))\n",
    "    #summary_stats.append(gen_summary_row(info, \"median\", np.nanmedian(hp_array)))\n",
    "\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f420c79-1763-48b0-b1cb-5a991f8d9ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime= 118.73780012130737\n"
     ]
    }
   ],
   "source": [
    "print(\"runtime=\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90d40-a6c2-44eb-aef7-4ce38111296b",
   "metadata": {},
   "source": [
    "# 6 depth, 6 counts, the slow way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20f5d51-697a-4e35-b6dd-7e9f15f08e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m     metric = CoaddM5Metric(unit=\u001b[33m\"\u001b[39m\u001b[33mCoadd \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (mags)\u001b[39m\u001b[33m\"\u001b[39m % filtername)\n\u001b[32m     13\u001b[39m     sl = Slicer(nside=\u001b[32m128\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     hp_array, info = \u001b[43msl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m#summary_stats.append(gen_summary_row(info, \"mean\", np.nanmean(hp_array)))\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m#summary_stats.append(gen_summary_row(info, \"median\", np.nanmedian(hp_array)))\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m subsets:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repos/25_scratch/maf_simple/slicer.py:427\u001b[39m, in \u001b[36mSlicer.__call__\u001b[39m\u001b[34m(self, input_visits, metric_s, info)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metric_s):\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache:\n\u001b[32m    426\u001b[39m         results[j][i] = metric.call_cached(\u001b[38;5;28mfrozenset\u001b[39m(slicedata[\u001b[33m\"\u001b[39m\u001b[33mobservationId\u001b[39m\u001b[33m\"\u001b[39m].tolist()),\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m                                            slicedata, slice_point=slice_i[\u001b[33m\"\u001b[39m\u001b[33mslice_point\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    429\u001b[39m         results[j][i] = metric(slicedata, slice_point=slice_i[\u001b[33m\"\u001b[39m\u001b[33mslice_point\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git_repos/25_scratch/maf_simple/slicer.py:88\u001b[39m, in \u001b[36mCoaddM5Metric.__call__\u001b[39m\u001b[34m(self, visits, slice_point)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, visits, slice_point=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.size(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisits\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfilter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) > \u001b[32m1\u001b[39m:\n\u001b[32m     89\u001b[39m         warnings.warn(\u001b[33m\"\u001b[39m\u001b[33mCoadding depths in different filters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.coadd(visits[\u001b[38;5;28mself\u001b[39m.col])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/rubin12/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:286\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    284\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/rubin12/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:353\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[39m\n\u001b[32m    351\u001b[39m     aux = ar[perm]\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     aux = ar\n\u001b[32m    355\u001b[39m mask = np.empty(aux.shape, dtype=np.bool)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#summary_stats = []\n",
    "subsets = {}\n",
    "for filtername in 'ugrizy':\n",
    "    subsets[filtername] = np.where(df[\"filter\"] == filtername)[0]\n",
    "#subsets[\"all\"] = np.arange(np.size(df[\"filter\"]))\n",
    "\n",
    "for key in subsets:\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    sub_data = df.iloc[np.where(df[\"filter\"] == filtername)[0]]\n",
    "    metric = CoaddM5Metric(unit=\"Coadd %s (mags)\" % filtername)\n",
    "    sl = Slicer(nside=128)\n",
    "    hp_array, info = sl(sub_data, metric, info=info)\n",
    "    #summary_stats.append(gen_summary_row(info, \"mean\", np.nanmean(hp_array)))\n",
    "    #summary_stats.append(gen_summary_row(info, \"median\", np.nanmedian(hp_array)))\n",
    "\n",
    "for key in subsets:\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    sub_data = df.iloc[np.where(df[\"filter\"] == filtername)[0]]\n",
    "    metric = CountMetric(unit=\"Coadd %s (mags)\" % filtername)\n",
    "    sl = Slicer(nside=128)\n",
    "    hp_array, info = sl(sub_data, metric, info=info)\n",
    "    #summary_stats.append(gen_summary_row(info, \"mean\", np.nanmean(hp_array)))\n",
    "    #summary_stats.append(gen_summary_row(info, \"median\", np.nanmedian(hp_array)))\n",
    "\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5892ab-ece8-4a34-b07d-ce2d62ec9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"runtime=\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66e21c-5b96-450f-8614-7809cf14ef8f",
   "metadata": {},
   "source": [
    "# 6 depths, 6 counts the fast way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcabe3d-3ba5-4fa1-a238-d1d4de4c8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to run two things on the same slicer\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "#summary_stats = []\n",
    "subsets = {}\n",
    "for filtername in 'ugrizy':\n",
    "    subsets[filtername] = np.where(df[\"filter\"] == filtername)[0]\n",
    "#subsets[\"all\"] = np.arange(np.size(df[\"filter\"]))\n",
    "\n",
    "for key in subsets:\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    sub_data = df.iloc[np.where(df[\"filter\"] == filtername)[0]]\n",
    "    metric = CoaddM5Metric(unit=\"Coadd %s (mags)\" % filtername)\n",
    "    metrics = [metric]\n",
    "    infos = [info]\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    metrics.append(CountMetric(unit=\"Coadd %s (mags)\" % filtername))\n",
    "    infos.append(info)\n",
    "    \n",
    "    sl = Slicer(nside=128)\n",
    "    hp_array, info = sl(sub_data, metrics, info=infos)\n",
    "    \n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac107aff-4e78-4139-9204-aa79e60af653",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"runtime=\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56573256-b932-43aa-840e-995dd36c7e9f",
   "metadata": {},
   "source": [
    "# 6 depths 6 counts the fast way, turn off cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99722124-6a9a-4f47-9877-80d92d78fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "#summary_stats = []\n",
    "subsets = {}\n",
    "for filtername in 'ugrizy':\n",
    "    subsets[filtername] = np.where(df[\"filter\"] == filtername)[0]\n",
    "#subsets[\"all\"] = np.arange(np.size(df[\"filter\"]))\n",
    "\n",
    "for key in subsets:\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    sub_data = df.iloc[np.where(df[\"filter\"] == filtername)[0]]\n",
    "    metric = CoaddM5Metric(unit=\"Coadd %s (mags)\" % filtername)\n",
    "    metrics = [metric]\n",
    "    infos = [info]\n",
    "    info = {\"run_name\": \"baseline_v4.3.1_0yrs\"}\n",
    "    info[\"observations_subset\"] =  \"filter=%s\" % key\n",
    "    metrics.append(CountMetric(unit=\"Coadd %s (mags)\" % filtername))\n",
    "    infos.append(info)\n",
    "    \n",
    "    sl = Slicer(nside=128, cache=False)\n",
    "    hp_array, info = sl(sub_data, metrics, info=infos)\n",
    "    \n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83132632-0045-4ca7-b389-6be3247f7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"runtime=\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a41d38-67e5-4f72-ab47-86faed85c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I bet this is pandas indexing vs numpy indexing slowing things down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856a099-0919-48f2-ba1c-0e0b5233898b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
